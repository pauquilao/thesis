{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Author: Paulo Quilao\n",
    "# MS Geomatics Engineering Thesis\n",
    "# Simulation of landslides using Cellular Automata\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import imageio\n",
    "import gdal\n",
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def read_raster(file):\n",
    "    \"\"\"Reads image file and returns its data source and converted numpy array.\"\"\"\n",
    "    data_source = gdal.Open(file)\n",
    "    band = data_source.GetRasterBand(1).ReadAsArray()\n",
    "    return (data_source, band)\n",
    "\n",
    "\n",
    "def create_png(path):\n",
    "    \"\"\"Creates PNG images based on GeoTiff files.\"\"\"\n",
    "    folder = \"png\"\n",
    "    op = os.path.join(path, folder)\n",
    "    if not os.path.exists(op):\n",
    "        os.makedirs(op)\n",
    "\n",
    "    search = os.path.join(path, \"*.tif\")\n",
    "    tif_paths = glob.glob(search)\n",
    "    # Arrange the paths per row\n",
    "    regex = re.compile(r\"\\d+\")  # this will match the suffix row\n",
    "    sorted_tif_paths = sorted(tif_paths, key=lambda p: int(regex.search(p).group(0)))\n",
    "    options_list = [\"-ot Byte\", \"-of PNG\", \"-b 1\", \"-scale\", \"-outsize 1000% 1000%\"]\n",
    "    options_string = \" \".join(options_list)\n",
    "    for tif in sorted_tif_paths:\n",
    "        out_fn = f\"ls_pred_{regex.findall(tif)[-1]}.png\"\n",
    "        gdal.Translate(os.path.join(op, out_fn), tif, options=options_string)\n",
    "\n",
    "    if os.path.isdir(op):\n",
    "        print(\"\\nDone converting tif image to png file.\")\n",
    "    else:\n",
    "        print(\"\\nFailed to convert tif images to png.\")\n",
    "\n",
    "\n",
    "def create_gif(path, out_fn, reverse=False):\n",
    "    \"\"\"Generates GIF based on series of passed images.\"\"\"\n",
    "    print(\"\\nCreating GIF...\")\n",
    "    image_paths = glob.glob(os.path.join(path, r\"*.png\"))\n",
    "    output_gif_path = os.path.join(path, out_fn)\n",
    "    # Arrange the paths per row\n",
    "    regex = re.compile(r\"\\d+\")  # this will match the suffix row\n",
    "    sorted_path = sorted(image_paths, key=lambda p: int(regex.findall(p)[1]), reverse=reverse)  # findall was used since sub folder is named run_{number}\n",
    "    # Save the animation to disk with 48 ms durations\n",
    "    imageio.mimsave(output_gif_path, [imageio.imread(fp) for fp in sorted_path], duration=0.48, subrectangles=True)\n",
    "    if os.path.isfile(output_gif_path):\n",
    "        print(\"GIF successfully exported.\")\n",
    "    else:\n",
    "        print(\"\\nFailed to create GIF.\")\n",
    "\n",
    "\n",
    "def clip_raster(polygon, raster):\n",
    "    \"\"\"Masks raster using polygon coverage.\"\"\"\n",
    "    with fiona.open(polygon, \"r\") as shapefile, rasterio.open(raster) as src:\n",
    "        mask = [feature[\"geometry\"] for feature in shapefile]\n",
    "        out_image, out_transform = rasterio.mask.mask(src, mask)  # out_image -> numpy array\n",
    "\n",
    "    return out_image\n",
    "\n",
    "# end of helper functions\n",
    "\n",
    "\n",
    "class Factors:\n",
    "    def __init__(self, **params):   # keys are flow_dir, and lsi\n",
    "        self.lsi_arr = clip_raster(params[\"extent\"], params[\"lsi\"])[0]\n",
    "        self.flow_dir_arr = clip_raster(params[\"extent\"], params[\"flow_dir\"])[0]\n",
    "        self.check_shape()\n",
    "\n",
    "    def check_shape(self):\n",
    "        \"\"\"Validates shape of input factors.\"\"\"\n",
    "        print(\"Checking shapes of input growth factors...\")\n",
    "        if self.flow_dir_arr.shape == self.lsi_arr.shape:\n",
    "            self.row = self.flow_dir_arr.shape[0]\n",
    "            self.col = self.flow_dir_arr.shape[1]\n",
    "            print(\"Input factors have the same shape.\")\n",
    "        else:\n",
    "            raise AttributeError(\"Shape of factors does not match.\")\n",
    "\n",
    "\n",
    "class Cellular_Automata:\n",
    "    def __init__(self, factors, neigh_size):\n",
    "        self.factors = factors\n",
    "        self.neigh_size = tuple([neigh_size] * 2)  # kernel dimension\n",
    "        self.dt = datetime.datetime.now().strftime(\"%x %X\")\n",
    "\n",
    "    def set_threshold(self, **params):\n",
    "        \"\"\"\n",
    "        Computes the flow direction and lsi thresholds to be considered in the moore neighborhood.\n",
    "        Params: actual landslide, initial cell, and limit (keys: \"actual_ls\", \"initial_cell\", limit\")\n",
    "        \"\"\"\n",
    "        self.data_source, self.initial_cell = read_raster(params[\"initial_cell\"])\n",
    "        self.initial_cell = self.initial_cell.astype(int)\n",
    "\n",
    "        assert self.initial_cell.shape == self.factors.lsi_arr.shape, \"Shape of initial cell should match shape of factors.\"\n",
    "\n",
    "        # Get the center pixel of the kernel\n",
    "        cent = int((self.neigh_size[0] - 2) - (self.neigh_size[0] - 3) / 2)\n",
    "        self.center = tuple([cent] * 2)\n",
    "        self.index = np.where(self.initial_cell == 1)\n",
    "\n",
    "        # Flow dir path\n",
    "        self.flow_path = {0: (0, 1), 1: (1, 1), 2: (1, 0), 3: (1, -1), 4: (0, -1), 5: (-1, -1), 6: (-1, 0), 7: (-1, 1)}\n",
    "\n",
    "        # LSI threshold\n",
    "        self.lsi_threshold = params[\"lsi_thresh\"]\n",
    "\n",
    "    def simulate(self, export=False, run=None):\n",
    "        \"\"\"Implement CA using the growth factors and set thresholds.\"\"\"\n",
    "        start_time = time.time()\n",
    "        print(\"\\nSimulating landslide...\")\n",
    "        # landslide base\n",
    "        self.landslide_predicted = np.full_like(self.factors.lsi_arr, 0)\n",
    "        self.landslide_predicted[self.index] = 1\n",
    "        row = col = self.neigh_size[0] - 1  # row and col increment every iteration\n",
    "        first_ite = 0  # counter for the creation of sub folder for the 1st row with data val\n",
    "        iteration = 0  # time step counter\n",
    "\n",
    "        # Orientation of landslide\n",
    "        if self.index[0][0] < (self.factors.row) // 2:  # failure originates from North\n",
    "            orientation = range(self.index[0][0] + 1, self.factors.row - 1)\n",
    "        else:\n",
    "            orientation = range(self.index[0][0] + 1, 0, -1)  # failure originates from South\n",
    "\n",
    "        for i in orientation:\n",
    "            if np.isin(self.landslide_predicted[i-1], [1]).sum():  # -1 to start in the next row after a row with landslide pixel\n",
    "                for j in range(1, self.factors.col - 1):\n",
    "                    try:\n",
    "                        # Flow dir kernel\n",
    "                        kernel_fd = self.factors.flow_dir_arr[i-1:i+row, j-1:j+col]\n",
    "                        kernel_fd[self.center] = -1\n",
    "                        # LSI kernel\n",
    "                        kernel_LSI = self.factors.lsi_arr[i-1:i+row, j-1:j+col]\n",
    "                        # Predicted landslide\n",
    "                        kernel_pred_ls = self.landslide_predicted[i-1:i+row, j-1:j+col]\n",
    "\n",
    "                        # Mean thresholds\n",
    "                        mean_LSI = np.delete(kernel_LSI.flatten(), (np.prod(self.neigh_size) // self.neigh_size[0] + 1), 0).mean()\n",
    "                        mean_rf = np.delete(kernel_rf.flatten(), (np.prod(self.neigh_size) // self.neigh_size[0] + 1), 0).mean()\n",
    "\n",
    "                        # Check each element in the flow dir kernel\n",
    "                        # for suitable flow\n",
    "                        for val in np.ndenumerate(kernel_fd):\n",
    "                            row_ = val[0][0]\n",
    "                            col_ = val[0][1]\n",
    "                            if val[1] in self.flow_path:\n",
    "                                k = self.flow_path[val[1]][0]\n",
    "                                l = self.flow_path[val[1]][1]\n",
    "                                try:\n",
    "                                    #  If a possible flow is seen\n",
    "                                    # stop the loop\n",
    "                                    while kernel_fd[row_, col_] != -1:\n",
    "                                        flow = kernel_fd[row, col]\n",
    "                                        k = self.flow_path[flow][0]\n",
    "                                        l = self.flow_path[flow][1]\n",
    "                                        row_ += k\n",
    "                                        col_ += l\n",
    "                                        if np.isin(kernel_pred_ls, [1]).sum() >= 1:\n",
    "                                            if kernel_fd[row_, col_] == -1:\n",
    "                                                if mean_LSI >= 0.75:\n",
    "                                                    self.landslide_predicted[i, j] = 1\n",
    "                                                else:\n",
    "                                                    self.landslide_predicted[i, j] = 0\n",
    "\n",
    "                                except (IndexError, KeyError):\n",
    "                                    continue\n",
    "                                break  # if a suitable flow is already seen\n",
    "                    # If raster dimension is not divisible by the kernel size\n",
    "                    except IndexError:\n",
    "                        continue\n",
    "\n",
    "                iteration += 1\n",
    "\n",
    "            # Export image for each row\n",
    "            if export:\n",
    "                main_folder = \"runs\"\n",
    "                op = os.path.join(os.getcwd(), main_folder)\n",
    "                if not os.path.exists(op):\n",
    "                    os.makedirs(op)\n",
    "\n",
    "                if first_ite == 0:\n",
    "                    # Create sub folder everytime export is invoked\n",
    "                    sub_folder = f\"run_{run}\"\n",
    "                    rel_path = os.path.join(os.getcwd(), main_folder, sub_folder)\n",
    "                    if os.path.isdir(rel_path):\n",
    "                        regex = re.compile(r\"\\d+$\")\n",
    "                        folder_num = regex.search(rel_path).group(0)\n",
    "                        new_folder = rel_path.strip(folder_num) + str(int(folder_num) + 1)  # increment the folder num by 1\n",
    "                        rel_path = new_folder\n",
    "                        os.makedirs(rel_path)\n",
    "                        first_ite += 1\n",
    "                    else:\n",
    "                        os.makedirs(os.path.join(rel_path))\n",
    "                        first_ite += 1\n",
    "\n",
    "                fn = f\"ls_{row+1}x{col+1}_pred_\" + str(i) + \".tif\"\n",
    "                self.export_predicted(os.path.join(rel_path, fn))\n",
    "\n",
    "        end_time = time.time() - start_time\n",
    "        display = f\"\\nFinished implementing CA after {end_time:.2f} seconds.\" if export else f\"Finished implementing CA after {end_time:.2f} seconds.\"\n",
    "        print(display)\n",
    "        print(f\"Number of iterations: {iteration}\")\n",
    "        return self.landslide_predicted\n",
    "\n",
    "    def check_accuracy(self):\n",
    "        \"\"\"Returns spatial accuracy of simulated landslide.\"\"\"\n",
    "        # Actual ls\n",
    "        actual_ls_pixels = np.count_nonzero(self.actual_ls == 1)\n",
    "        # Simulated ls\n",
    "        sim_ls_pixels = np.isin(self.landslide_predicted, [1, 0]).sum()\n",
    "        # Correct predictions\n",
    "        intersection = self.actual_ls * self.landslide_predicted\n",
    "        correct_pixels = np.count_nonzero(intersection == 1)\n",
    "        percentage = (correct_pixels / (actual_ls_pixels + (abs(sim_ls_pixels - correct_pixels)))) * 100\n",
    "        print(\"-\" * 57)  # divider\n",
    "        self.summary = f\"Actual: {actual_ls_pixels} | Simulated: {sim_ls_pixels} | TP: {correct_pixels}\"\n",
    "        self.accuracy = f\"Accuracy of simulated landslide: {percentage:.2f}%\"\n",
    "        print(self.summary)\n",
    "        print(self.accuracy)\n",
    "\n",
    "    def save_summary(self, landslide_id, filename):\n",
    "        \"\"\"Exports information of simulated landslide to a text file.\"\"\"\n",
    "        current_dir = os.getcwd()\n",
    "        folders = r\"runs\\summary\"\n",
    "        out_path = os.path.join(current_dir, folders)\n",
    "        if not os.path.isdir(folders):\n",
    "            os.makedirs(out_path)\n",
    "        with open(os.path.join(out_path, filename), \"a\") as out_file:\n",
    "            try:\n",
    "                out_file.write(self.dt + \"\\n\")\n",
    "                out_file.write(f\"Landslide ID: {str(landslide_id)}\\n\")\n",
    "                out_file.write(f\"Neighborhood size: {self.neigh_size} Threshold: +-{self.limit}\\n\")\n",
    "                out_file.write(self.summary + \"\\n\")\n",
    "                out_file.write(self.accuracy + \"\\n\\n\")\n",
    "\n",
    "            except Exception:\n",
    "                raise AttributeError(\"Cannot export summary unless save_summary method was invoked.\")\n",
    "\n",
    "    def export_predicted(self, out_fn):\n",
    "        \"\"\"Exports simulated landslide to a GeoTiff raster.\"\"\"\n",
    "        print(\"\\nExporting array to GTiff...\")\n",
    "        driver = gdal.GetDriverByName(\"GTiff\")\n",
    "        out_data = driver.Create(out_fn, self.factors.col, self.factors.row, 1, gdal.GDT_Int16)\n",
    "        out_data.SetGeoTransform(self.data_source.GetGeoTransform())\n",
    "        out_data.SetProjection(self.data_source.GetProjection())\n",
    "        out_data.GetRasterBand(1).WriteArray(self.landslide_predicted)\n",
    "        out_data.GetRasterBand(1).SetNoDataValue(-999)\n",
    "        out_data.FlushCache()\n",
    "        out_data = None\n",
    "\n",
    "        # check if exported\n",
    "        if os.path.isfile(out_fn):\n",
    "            print(\"Simulated landslide exported.\")\n",
    "        else:\n",
    "            print(\"Failed to export raster.\")\n",
    "\n",
    "    def get_shape(self):\n",
    "        print(\"factors\", self.factors.row, self.factors.col)\n",
    "        print(\"initial cell\", self.initial_cell.shape)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ls_id = \"kating\"\n",
    "    flow_dir = \"D:\\\\ms gme\\\\thesis\\\\final parameters\\\\ca\\\\Hypothetical_LS\\\\itogon_flow_dir.tif\"\n",
    "    lsi = \"D:\\\\ms gme\\\\thesis\\\\final parameters\\\\ca\\\\Hypothetical_LS\\\\itogon_lsi.tif\"\n",
    "    initial_cell = f\"D:\\\\ms gme\\\\thesis\\\\final parameters\\\\ca\\\\Hypothetical_LS\\\\{ls_id}_initial_cell.tif\"\n",
    "    bounds = f\"D:\\\\ms gme\\\\thesis\\\\final parameters\\\\ca\\\\Hypothetical_LS\\\\shp\\\\{ls_id}_hypo_extent.shp\"\n",
    "\n",
    "    # Initialize factors\n",
    "    factors = {\"flow_dir\": flow_dir, \"lsi\": lsi, \"extent\": bounds}\n",
    "    growth_factors = Factors(**factors)\n",
    "\n",
    "    # Initialize CA and kernel size\n",
    "    kernel = 3  # 3x3 moore neighborhood\n",
    "    ca_model = Cellular_Automata(growth_factors, kernel)\n",
    "\n",
    "    # Set thresholds\n",
    "    lsi_threshold = 0.75  # user-defined lsi treshold for to be considered in the kernel\n",
    "    thresholds = {\"initial_cell\": initial_cell, \"lsi_thresh\": lsi_threshold}\n",
    "    ca_model.set_threshold(**thresholds)\n",
    "\n",
    "    # Perform simulation\n",
    "#     runs = \"D:/ms gme/thesis/final parameters/ca/runs\"\n",
    "#     r_path = [folder for folder in os.listdir(runs) if not os.path.isfile(folder) and folder.startswith(\"run\")]\n",
    "#     run_num = int(r_path[-1][-1]) + 1\n",
    "#     exports = {\"export\": True, \"run\": run_num}  # optional, if export is set to True\n",
    "    ca_model.simulate()\n",
    "\n",
    "    # Export predicted landslide\n",
    "    image = f\"D:\\\\ms gme\\\\thesis\\\\final parameters\\\\ca\\\\Hypothetical_LS\\\\outputs\\\\{ls_id}_{kernel}x{kernel}.tif\"\n",
    "    ca_model.export_predicted(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create png from tiff images\n",
    "    create_png(path)\n",
    "    \n",
    "    # Create a GIF from png images\n",
    "    png_path = f\"D:/ms gme/thesis/final parameters/ca/runs/run_{run_num}/png\"\n",
    "    fn = f\"ls{ls_id}_{kernel}_{kernel}.gif\"\n",
    "    create_gif(png_path, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "gis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "612px",
    "left": "26px",
    "top": "129.4px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 237.6,
   "position": {
    "height": "259.2px",
    "left": "916.6px",
    "right": "20px",
    "top": "143px",
    "width": "516.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
